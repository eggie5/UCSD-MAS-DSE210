{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "I did some preprocessing of the dataset w/ my utils library that I imported in the above cell. We then load the training data and the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '20news-bydate-matlab/matlab'\n",
    "features = utils.read_features(\"expanded.txt\")\n",
    "targets = utils.read_label(path, 'train.label')\n",
    "vocab = utils.read_vocab(\"vocabulary.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "Next we import and setup my classifier which I have packaged into the `NaiveBayesClassifier` class. We then pass it the training examples and see how long it takes to train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training examples: 11269\n",
      "Total targets: 20\n",
      "Buildign vocabulary from user input\n",
      "Vocabulary count: 61188\n",
      "Estimated iterations: 1223760\n",
      "training step 1...\n",
      "training step 2...\n",
      "Training Complete: 33.6298668385s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import naive_bayes_classifier as lib\n",
    "\n",
    "clf =  lib.NaiveBayesClassifier(\"\")\n",
    "clf.train(features, targets, vocab=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify\n",
    "\n",
    "The training took about 30 seconds. Now lets test our classifier on the test dataset. We will feed it examples and compare the predicted output the the known answers in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5364/7505\n",
      "0.714723517655\n"
     ]
    }
   ],
   "source": [
    "answer_label_array = utils.read_label(path, 'test.label')\n",
    "test_features = utils.read_features(\"test_expanded.txt\")\n",
    "\n",
    "correct_count = 0\n",
    "for i in range(len(answer_label_array)):\n",
    "    expected = clf.predict(test_features[i])\n",
    "    actual = answer_label_array[i]\n",
    "    if expected == actual:\n",
    "        correct_count+=1\n",
    "        \n",
    "\n",
    "print \"{0}/{1}\".format(correct_count, len(answer_label_array))\n",
    "print float(correct_count)/len(answer_label_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Results\n",
    "\n",
    "So as you can see the classifier has a 28% error rate. This error rate could possibly be lowered by the use of differnent smoothing techniques or stop word analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
